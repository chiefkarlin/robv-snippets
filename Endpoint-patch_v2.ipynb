{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdac9726-ebec-4bb5-bff2-a815b2c75850",
   "metadata": {},
   "source": [
    "### Documentation References:\n",
    "* Use google-cloud-sdk version 1.20.0\n",
    "* From the GAPIC client - [Endpoint Service Client](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.endpoint_service.EndpointServiceClient)\n",
    "* [Update Endpoint](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.endpoint_service.EndpointServiceClient#google_cloud_aiplatform_v1_services_endpoint_service_EndpointServiceClient_update_endpoint)\n",
    "* [Endpoint Class](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.Endpoint)\n",
    "* [Request-Response-Logging-Config](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.PredictRequestResponseLoggingConfig)\n",
    "* [BigQueryDestination](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.BigQueryDestination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67165dc3-2b30-475a-8c32-4d2a81179c9a",
   "metadata": {},
   "source": [
    "### Update via the GAPIC SDK\n",
    "The following cell shows an example of enabling request response logging via the `aiplatform_v1` GAPIC (Google API Compiler) SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d42d399-c3e9-4f6c-bd78-c5ed6d61aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: projects/357746845324/locations/us-central1/endpoints/8031541014764191744\n",
      "PredictRequestResponseLoggingConfig: enabled: true\n",
      "sampling_rate: 0.3\n",
      "bigquery_destination {\n",
      "  output_uri: \"bq://gcp-ml-sandbox.scratch.endpoint_8031541014764191744_predict_req_resp_log\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform_v1\n",
    "from google.cloud.aiplatform_v1.types import Endpoint,PredictRequestResponseLoggingConfig, BigQueryDestination\n",
    "from google.protobuf import field_mask_pb2 as field_mask\n",
    "\n",
    "PROJECT='gcp-ml-sandbox'\n",
    "REGION='us-central1'\n",
    "ENDPOINT_ID='8031541014764191744'\n",
    "\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Logging destination\n",
    "BQ_DATASET=\"scratch\"\n",
    "BQ_TABLE=f\"endpoint_{ENDPOINT_ID}_predict_req_resp_log\"\n",
    "\n",
    "\n",
    "def enable_predict_request_response_logging():\n",
    "    \n",
    "    client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "    endpoint_name = f\"projects/{PROJECT}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    "\n",
    "    \n",
    "    \n",
    "    endpoint = aiplatform_v1.Endpoint(\n",
    "        {\"name\":endpoint_name,\n",
    "         \"predict_request_response_logging_config\" : \n",
    "             PredictRequestResponseLoggingConfig(\n",
    "                 {\n",
    "                    \"enabled\":True,\n",
    "                    \"sampling_rate\":.3, # Float value between 0 and 1\n",
    "                    \"bigquery_destination\": \n",
    "                         BigQueryDestination({\"output_uri\":f\"bq://{PROJECT}.{BQ_DATASET}.{BQ_TABLE}\"})\n",
    "                 }\n",
    "             )\n",
    "        }\n",
    "    )\n",
    "    update_mask = field_mask.FieldMask(paths=['predict_request_response_logging_config'])\n",
    "    \n",
    "    \n",
    "\n",
    "    request = aiplatform_v1.UpdateEndpointRequest(\n",
    "        endpoint=endpoint,\n",
    "        update_mask=update_mask\n",
    "    )\n",
    "    \n",
    "    # Make the request\n",
    "    client = aiplatform_v1.EndpointServiceClient(client_options=client_options)\n",
    "    response =  client.update_endpoint(request=request)\n",
    "\n",
    "    # Handle the response\n",
    "    print(f\"Endpoint: {response.name}\\nPredictRequestResponseLoggingConfig: {response.predict_request_response_logging_config}\")\n",
    "\n",
    "\n",
    "enable_predict_request_response_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05323c-7991-4833-9ec0-da0ff992d3d0",
   "metadata": {},
   "source": [
    "Double checking the output by running `get_endpoint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37dc1544-fd28-487f-bc27-123fa7556477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: projects/357746845324/locations/us-central1/endpoints/8031541014764191744\n",
      "PredictRequestResponseLoggingConfig: enabled: true\n",
      "sampling_rate: 0.3\n",
      "bigquery_destination {\n",
      "  output_uri: \"bq://gcp-ml-sandbox.scratch.endpoint_8031541014764191744_predict_req_resp_log\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform_v1\n",
    "from google.cloud.aiplatform_v1.types import Endpoint,PredictRequestResponseLoggingConfig, BigQueryDestination\n",
    "from google.protobuf import field_mask_pb2\n",
    "\n",
    "PROJECT='gcp-ml-sandbox'\n",
    "REGION='us-central1'\n",
    "ENDPOINT_ID='8031541014764191744'\n",
    "\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "def get_endpoint():\n",
    "    # Create a client\n",
    "    client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "    endpoint_name = f\"projects/{PROJECT}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    "    \n",
    "    client = aiplatform_v1.EndpointServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    request = aiplatform_v1.GetEndpointRequest(\n",
    "        name=endpoint_name,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    response = client.get_endpoint(request=request)\n",
    "\n",
    "    # Handle the response\n",
    "    print(f\"Endpoint: {response.name}\\nPredictRequestResponseLoggingConfig: {response.predict_request_response_logging_config}\")\n",
    "\n",
    "get_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06cc7d2e-aa54-4582-be91-7b66af84fdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects//357746845324/locations/us-central1/endpoints/8031541014764191744'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_URI = \"https://us-central1-aiplatform.googleapis.com/v1/projects/357746845324/locations/us-central1/endpoints/8031541014764191744\"\n",
    "endpoint_name = f\"projects/{ENDPOINT_URI.split ('/projects')[1]}\"\n",
    "endpoint_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4b6c7-1a29-404f-bfc7-b9c2a6401511",
   "metadata": {},
   "source": [
    "### Custom Component and Pipeline Definition\n",
    "In the following cell, a python-based custom component is used to wrap the SDK call and handle pipeline artifacts for input and output\n",
    "The pipeline definition also uses the [dsl.importer](https://www.kubeflow.org/docs/components/pipelines/v1/sdk-v2/importer-component/) to bring in a reference to the Artifact URI from a prior pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b848e240-56ac-4fac-9bb5-6f9a95cb3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler, dsl\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "\n",
    "BASE_DIR = \"gs://gcp-ml-sandbox-scratch/endpoint-patch\"\n",
    "PIPELINE_ROOT = f\"{BASE_DIR}/pipeline-root\"\n",
    "\n",
    "################################################################\n",
    "# Simple Custom Component to Patch a Vertex Endpoint using the \n",
    "# aiplatform_v1 GAPIC SDK\n",
    "# to enable Vertex request-response logging\n",
    "\n",
    "################################################################\n",
    "\n",
    "@dsl.component(base_image='python:3.9-slim',\n",
    "           packages_to_install=['google-cloud-aiplatform'])\n",
    "\n",
    "def enable_request_response_logging(\n",
    "    input_endpoint: dsl.Input[dsl.Artifact],\n",
    "    updated_endpoint: dsl.Output[dsl.Artifact],\n",
    "    bq_log_destination: str,\n",
    "    sampling_rate: float,\n",
    "    project: str,\n",
    "    region: str=\"us-central1\",\n",
    "):\n",
    "    from google.cloud import aiplatform_v1\n",
    "    from google.cloud.aiplatform_v1.types import Endpoint,PredictRequestResponseLoggingConfig, BigQueryDestination\n",
    "    from google.protobuf import field_mask_pb2 as field_mask\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    # Grabbing a path to the Endpoint URI from the google.VertexEndpoint artifact\n",
    "    endpoint_name = f\"projects{input_endpoint.uri.split ('/projects')[1]}\"\n",
    "    \n",
    "    endpoint = aiplatform_v1.Endpoint(\n",
    "        {\"name\":endpoint_name,\n",
    "         \"predict_request_response_logging_config\" : \n",
    "             PredictRequestResponseLoggingConfig(\n",
    "                 {\n",
    "                    \"enabled\":True,\n",
    "                    \"sampling_rate\":sampling_rate, # Float value between 0 and 1\n",
    "                    \"bigquery_destination\": \n",
    "                         BigQueryDestination({\"output_uri\":bq_log_destination})\n",
    "                 }\n",
    "             )\n",
    "        }\n",
    "    )\n",
    "    update_mask = field_mask.FieldMask(paths=['predict_request_response_logging_config'])\n",
    "\n",
    "    request = aiplatform_v1.UpdateEndpointRequest(\n",
    "        endpoint=endpoint,\n",
    "        update_mask=update_mask\n",
    "    )\n",
    "    \n",
    "    # Make the request\n",
    "    api_endpoint = \"{}-aiplatform.googleapis.com\".format(region)\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    \n",
    "    print(f\"API Endpoint: {api_endpoint}\")\n",
    "    \n",
    "    client = aiplatform_v1.EndpointServiceClient(client_options=client_options)\n",
    "    response =  client.update_endpoint(request=request)\n",
    "\n",
    "    # Handle the response\n",
    "    print(f\"Endpoint: {response.name}\\nPredictRequestResponseLoggingConfig: {endpoint.predict_request_response_logging_config}\")\n",
    "    \n",
    "    #Copying the input artifact object to the output artifact\n",
    "    updated_endpoint = copy.copy(input_endpoint)\n",
    "    \n",
    "    \n",
    "\n",
    "####################################################################\n",
    "# Pipeline Definition\n",
    "####################################################################\n",
    "    \n",
    "\n",
    "@dsl.pipeline(pipeline_root=PIPELINE_ROOT, name=\"endpoint-patch-example\")\n",
    "def endpoint_pipeline(\n",
    "    bq_log_destination: str,\n",
    "    project: str,\n",
    "    region: str,\n",
    "    endpoint_uri: str,\n",
    "    sampling_rate: float\n",
    "):\n",
    "    endpoint_uri=endpoint_uri\n",
    "    \n",
    "    endpoint_task = dsl.importer(\n",
    "        artifact_uri=endpoint_uri,\n",
    "        artifact_class=artifact_types.VertexEndpoint,\n",
    "      ).set_display_name('Import endpoint')\n",
    "    \n",
    "    _ = enable_request_response_logging(\n",
    "            input_endpoint=endpoint_task.output,\n",
    "            bq_log_destination=bq_log_destination,\n",
    "            sampling_rate=sampling_rate,\n",
    "            project=project,\n",
    "            region=region\n",
    "        ).set_display_name(\"Patching Endpoint\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d6dda-8690-4c07-a919-74b2f26cf071",
   "metadata": {},
   "source": [
    "### Run Pipeline and patch endpoint\n",
    "The following cell shows compiling and running the pipeline, passing in an existing artifact URI for the endpoint as a parameter.  If not using the `dsl.Importer`, you can pass in a VertexEndpoint to the custom component created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "11537f7a-8b50-4ece-9b16-96b26044e3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/357746845324/locations/us-central1/pipelineJobs/endpoint-patch-example-20221222164933\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/357746845324/locations/us-central1/pipelineJobs/endpoint-patch-example-20221222164933')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/endpoint-patch-example-20221222164933?project=357746845324\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "### Setup Pipeline parameters for this example\n",
    "### and run pipeline\n",
    "\n",
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "PIPELINE_SPEC='endpoint_pipeline.json'\n",
    "BASE_DIR = \"gs://gcp-ml-sandbox-scratch/endpoint-patch\"\n",
    "PIPELINE_ROOT = f\"{BASE_DIR}/pipeline-root\"\n",
    "\n",
    "PROJECT='gcp-ml-sandbox'\n",
    "REGION='us-central1'\n",
    "ENDPOINT_URI = \"https://us-central1-aiplatform.googleapis.com/v1/projects/357746845324/locations/us-central1/endpoints/8031541014764191744\"\n",
    "\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Logging destination\n",
    "BQ_DATASET=\"scratch\"\n",
    "BQ_TABLE=f\"endpoint_{ENDPOINT_ID}_predict_req_resp_log\"\n",
    "BQ_LOG_DESTINATION=f\"bq://{PROJECT}.{BQ_DATASET}.{BQ_TABLE}\"\n",
    "\n",
    "SAMPLING_RATE=.35\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=endpoint_pipeline,\n",
    "        package_path=PIPELINE_SPEC)\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=f\"pipeline_endpoint_patch_{TIMESTAMP}\",\n",
    "    template_path=PIPELINE_SPEC,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        \"project\": PROJECT,\n",
    "        \"region\": REGION,\n",
    "        \"bq_log_destination\": BQ_LOG_DESTINATION,\n",
    "        \"endpoint_uri\": ENDPOINT_URI,\n",
    "        \"sampling_rate\":SAMPLING_RATE\n",
    "    }\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "py-3.9_tf-2.10_aip-1.20",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "py-3.9_tf-2.10_aip-1.20",
   "language": "python",
   "name": "py-3.9_tf-2.10_aip-1.20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
